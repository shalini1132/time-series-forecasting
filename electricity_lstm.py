# -*- coding: utf-8 -*-
"""electricity LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RcI_YET6eLmuo1XkIET45soj5tdDY6QH
"""

#import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error,mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
import shap

#Load dataset
df=pd.read_excel("/content/time_series_dataset.xlsx")

df.head()

#convert Date column
df['date']=pd.to_datetime(df['date'])

df

#sorting by date
df=df.sort_values('date')

df

#checking missing values

df.isnull().sum()

#Feature Engineering
df['day']=df['date'].dt.day
df['month']=df['date'].dt.month
df['year']=df['date'].dt.year
df['lag1']=df['energy_consumption'].shift(1)
df['rolling3']=df['energy_consumption'].rolling(3).mean()
df=df.dropna()

#select features
features=['temperature','humidity','wind_speed','pressure','day','month','lag1','rolling3','energy_consumption']
data=df[features]

#scaling
scaler=MinMaxScaler()
scaled=scaler.fit_transform(data)

#sequence creation
def create_sequences(data,window=7,target_index=8):
  x, y = [], []
  for i in range(len(data) - window):
    x.append(data[i:i+window])
    y.append(data[i+window,target_index])
  return np.array(x), np.array(y)

window=7
x, y = create_sequences(scaled,window)

#train-test split
train_size = int(len(x) * 0.80)
x_train, x_test = x[:train_size], x[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

#LSTM Model
model=Sequential([LSTM(64,return_sequences=True,input_shape=(x_train.shape[1],x_train.shape[2])),LSTM(32),Dense(1)])
model.compile(optimizer='adam',loss='mse')
model.fit(x_train,y_train,epochs=20,batch_size=32,validation_split=0.1,verbose=1)
y_pred=model.predict(x_test)

#evaluation
rmse=np.sqrt(mean_squared_error(y_test,y_pred))
mae=mean_absolute_error(y_test,y_pred)
print("Rmse:",rmse)
print('MAE:',mae)

#SHAP Explainability using surrogate model
x_train_flat=x_train.reshape(x_train.shape[0],-1)
x_test_flat=x_test.reshape(x_test.shape[0],-1)
surrogate=RandomForestRegressor()
surrogate.fit(x_train_flat,y_train)
explainer=shap.TreeExplainer(surrogate)
shap_values=explainer.shap_values(x_test_flat)
shap.summary_plot(shap_values,x_test_flat)

